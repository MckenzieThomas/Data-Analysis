{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85d7f868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6efe15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "beijingAirData = pd.read_csv(\"C:/Users/Studying/Data/PRSA_Data_Aotizhongxin_20130301-20170228.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aeae054",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (beijingAirData['PM2.5'] <=60) & (beijingAirData['PM10'] <=100) & (beijingAirData['SO2'] <= 80) & (beijingAirData['NO2'] <=80) & (beijingAirData['O3'] <= 100),\n",
    "    (beijingAirData['PM2.5'] > 61) | (beijingAirData['PM10'] >101) | (beijingAirData['SO2'] > 81) | (beijingAirData['NO2'] >81) | (beijingAirData['O3'] > 101)\n",
    "]\n",
    "\n",
    "values = [1, 2]\n",
    "\n",
    "beijingAirData['airQuality'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c6fb677",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = beijingAirData[ (beijingAirData['airQuality'] == 0)].index\n",
    "beijingAirData.drop(index , inplace=True)\n",
    "\n",
    "updated_beijingAirData = beijingAirData.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d81604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = updated_beijingAirData.drop(labels = ['year', 'month', 'day', 'hour', 'CO', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'wd', 'WSPM', 'station', 'airQuality'], axis = 1)\n",
    "label = updated_beijingAirData.drop(labels = ['No', 'year', 'month', 'day', 'hour', 'PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'wd', 'WSPM', 'station'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4af6d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>SO2</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>airQuality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012881</td>\n",
       "      <td>0.051524</td>\n",
       "      <td>0.051524</td>\n",
       "      <td>0.051524</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025553</td>\n",
       "      <td>0.102212</td>\n",
       "      <td>0.102212</td>\n",
       "      <td>0.051106</td>\n",
       "      <td>0.089435</td>\n",
       "      <td>0.983790</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040230</td>\n",
       "      <td>0.093869</td>\n",
       "      <td>0.093869</td>\n",
       "      <td>0.067049</td>\n",
       "      <td>0.134098</td>\n",
       "      <td>0.978918</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.053867</td>\n",
       "      <td>0.080801</td>\n",
       "      <td>0.080801</td>\n",
       "      <td>0.148136</td>\n",
       "      <td>0.148136</td>\n",
       "      <td>0.969615</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067328</td>\n",
       "      <td>0.040397</td>\n",
       "      <td>0.040397</td>\n",
       "      <td>0.161588</td>\n",
       "      <td>0.161588</td>\n",
       "      <td>0.969527</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         No     PM2.5      PM10       SO2       NO2        O3  airQuality\n",
       "0  0.012881  0.051524  0.051524  0.051524  0.090167  0.991837         1.0\n",
       "1  0.025553  0.102212  0.102212  0.051106  0.089435  0.983790         1.0\n",
       "2  0.040230  0.093869  0.093869  0.067049  0.134098  0.978918         1.0\n",
       "3  0.053867  0.080801  0.080801  0.148136  0.148136  0.969615         1.0\n",
       "4  0.067328  0.040397  0.040397  0.161588  0.161588  0.969527         1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_beijingAirData_normal = preprocessing.normalize(features)\n",
    "updated_beijingAirData_normal = pd.DataFrame(updated_beijingAirData_normal, columns = features.columns)\n",
    "updated_beijingAirData_normal['airQuality'] = label\n",
    "updated_beijingAirData_normal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9384bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(updated_beijingAirData_normal.drop(labels = [\"airQuality\"],axis = 1), label, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0e9a94",
   "metadata": {},
   "source": [
    "1. Повнозв'язані нейронні мережі\n",
    "Вирішіть завдання класифікації даних, з якими ви працювали в лабораторній № 1 за допомогою повнозв’язаної нейромережі прямого поширення (fully connected feed-forward network). Результати порівняйте з одержаними раніше. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b4609e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79b39f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66ad5351",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab355a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (60000, 28, 28)\n",
      "Training labels shape:  (60000,)\n",
      "Test data shape:  (10000, 28, 28)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "Y_train_categorical = utils.to_categorical(Y_train)\n",
    "Y_test_categorical = utils.to_categorical(Y_test)\n",
    "\n",
    "print(\"Training data shape: \", X_train.shape)\n",
    "print(\"Training labels shape: \", Y_train.shape)\n",
    "print(\"Test data shape: \", X_test.shape)\n",
    "print(\"Test labels shape: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32b55a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1257/1257 [==============================] - 12s 9ms/step - loss: 2.6597 - accuracy: 0.7545 - val_loss: 0.7461 - val_accuracy: 0.8202\n",
      "Epoch 2/10\n",
      "1257/1257 [==============================] - 10s 8ms/step - loss: 0.6121 - accuracy: 0.8463 - val_loss: 0.5289 - val_accuracy: 0.8778\n",
      "Epoch 3/10\n",
      "1257/1257 [==============================] - 8s 6ms/step - loss: 0.4344 - accuracy: 0.8844 - val_loss: 0.4085 - val_accuracy: 0.8899\n",
      "Epoch 4/10\n",
      "1257/1257 [==============================] - 8s 7ms/step - loss: 0.3499 - accuracy: 0.9079 - val_loss: 0.4049 - val_accuracy: 0.8993\n",
      "Epoch 5/10\n",
      "1257/1257 [==============================] - 9s 7ms/step - loss: 0.3014 - accuracy: 0.9192 - val_loss: 0.3183 - val_accuracy: 0.9226\n",
      "Epoch 6/10\n",
      "1257/1257 [==============================] - 9s 7ms/step - loss: 0.2665 - accuracy: 0.9281 - val_loss: 0.3250 - val_accuracy: 0.9198\n",
      "Epoch 7/10\n",
      "1257/1257 [==============================] - 10s 8ms/step - loss: 0.2480 - accuracy: 0.9318 - val_loss: 0.3140 - val_accuracy: 0.9297\n",
      "Epoch 8/10\n",
      "1257/1257 [==============================] - 10s 8ms/step - loss: 0.2301 - accuracy: 0.9376 - val_loss: 0.2866 - val_accuracy: 0.9294\n",
      "Epoch 9/10\n",
      "1257/1257 [==============================] - 8s 6ms/step - loss: 0.2259 - accuracy: 0.9412 - val_loss: 0.2755 - val_accuracy: 0.9368\n",
      "Epoch 10/10\n",
      "1257/1257 [==============================] - 8s 6ms/step - loss: 0.2083 - accuracy: 0.9435 - val_loss: 0.2767 - val_accuracy: 0.9349\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train_categorical, epochs=10, validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f4935a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18bb4465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2149 - accuracy: 0.9445\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.2856 - accuracy: 0.9362\n",
      "Classification accuracy on training set:  0.9445333480834961\n",
      "Classification accuracy on test set:  0.9362000226974487\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(X_train,  Y_train_categorical)\n",
    "test_loss, test_acc = model.evaluate(X_test,  Y_test_categorical)\n",
    "print('Classification accuracy on training set: ', train_acc)\n",
    "print('Classification accuracy on test set: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf1d5b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step\n",
      "Confusion matrix of the test set:\n",
      " tf.Tensor(\n",
      "[[ 946    0    0    1    2    0   15    0   13    3]\n",
      " [   0 1105    6    2    0    1    6    0   15    0]\n",
      " [   3    0  970    3    7    2    8    9   28    2]\n",
      " [   5    1   24  870    2   43    1   10   45    9]\n",
      " [   2    1    2    0  933    0   14    1    3   26]\n",
      " [   2    0    1   17    1  827   13    1   27    3]\n",
      " [   2    3    1    0    6   10  926    0   10    0]\n",
      " [   3    3   28   10    7    1    0  949    5   22]\n",
      " [   2    0    6   12    9   11   16    5  898   15]\n",
      " [   7    3    0   11   25    7    0    7   11  938]], shape=(10, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "test_predict = model.predict(X_test)\n",
    "test_predict_labels = np.argmax(test_predict, axis=1)\n",
    "confusion_matrix = tf.math.confusion_matrix(labels=Y_test, predictions=test_predict_labels)\n",
    "print('Confusion matrix of the test set:\\n', confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f810748",
   "metadata": {},
   "source": [
    "2. Згорткові нейронні мережі\n",
    "Вирішіть завдання класифікації зображень за допомогою згорткової (convolutional) нейромережі (якщо в обраному датасеті класів забагато, достатньо залишити 3-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "af9ce0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 586 images belonging to 3 classes.\n",
      "Found 194 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset_image_gen = ImageDataGenerator(rescale=1./255, validation_split=0.25)\n",
    "\n",
    "train_data = dataset_image_gen.flow_from_directory(\"C:/Users/Studying/Data/Dataset_BUSI_with_GT\", color_mode=\"grayscale\", batch_size=32, shuffle=True, class_mode='categorical', seed=42,\n",
    "                                                          subset='training')\n",
    "\n",
    "valid_data = dataset_image_gen.flow_from_directory(\"C:/Users/Studying/Data/Dataset_BUSI_with_GT\", color_mode=\"grayscale\", batch_size=32, shuffle=True, class_mode='categorical', seed=42,\n",
    "                                                          subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7a251654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 780 files belonging to 3 classes.\n",
      "Using 585 files for training.\n",
      "Found 780 files belonging to 3 classes.\n",
      "Using 195 files for validation.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "train_data_gen = image_dataset_from_directory(\n",
    "                  \"C:/Users/Studying/Data/Dataset_BUSI_with_GT\",\n",
    "                  validation_split=0.25,\n",
    "                  subset=\"training\",\n",
    "                  seed=42,\n",
    "                  image_size=(240, 240),\n",
    "                  batch_size=32)\n",
    "\n",
    "\n",
    "valid_data_gen = image_dataset_from_directory(\n",
    "                                       \"C:/Users/Studying/Data/Dataset_BUSI_with_GT\",\n",
    "                                        validation_split=0.25,\n",
    "                                        subset=\"validation\",\n",
    "                                        seed=42,\n",
    "                                        image_size=(240,240),\n",
    "                                        batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b185b119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352503\n",
      "739\n",
      "477\n",
      "<class 'tuple'>\n",
      "(477, 739, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "width, height = Image.open(\"C:/Users/Studying/Data/Dataset_BUSI_with_GT/normal/normal (130).png\").size\n",
    "print(width*height)\n",
    "print(width)\n",
    "print(height)\n",
    "\n",
    "im = cv2.imread(\"C:/Users/Studying/Data/Dataset_BUSI_with_GT/normal/normal (130).png\")\n",
    "print(type(im.shape))\n",
    "print(im.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "85cbddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu', input_shape=(240, 240, 3)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "33b859a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_75 (Conv2D)          (None, 238, 238, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_73 (MaxPoolin  (None, 119, 119, 16)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_76 (Conv2D)          (None, 117, 117, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_74 (MaxPoolin  (None, 58, 58, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_77 (Conv2D)          (None, 56, 56, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_75 (MaxPoolin  (None, 28, 28, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_78 (Conv2D)          (None, 26, 26, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_76 (MaxPoolin  (None, 13, 13, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 21632)             0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 128)               2769024   \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,874,915\n",
      "Trainable params: 2,874,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0387a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=(['accuracy'])\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "74ec28a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\",\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "65f960cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 17s 802ms/step - loss: 10.7520 - accuracy: 0.4667 - val_loss: 0.9309 - val_accuracy: 0.5333\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 16s 809ms/step - loss: 0.9285 - accuracy: 0.5966 - val_loss: 0.8672 - val_accuracy: 0.5538\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 15s 788ms/step - loss: 0.8108 - accuracy: 0.6410 - val_loss: 0.8678 - val_accuracy: 0.6051\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 15s 751ms/step - loss: 0.6813 - accuracy: 0.7111 - val_loss: 0.8431 - val_accuracy: 0.6564\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 15s 751ms/step - loss: 0.6097 - accuracy: 0.7453 - val_loss: 0.9100 - val_accuracy: 0.6769\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 15s 755ms/step - loss: 0.5278 - accuracy: 0.7932 - val_loss: 0.8944 - val_accuracy: 0.6872\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 16s 851ms/step - loss: 0.4017 - accuracy: 0.8427 - val_loss: 0.8096 - val_accuracy: 0.6974\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 15s 753ms/step - loss: 0.3023 - accuracy: 0.9060 - val_loss: 1.1069 - val_accuracy: 0.6821\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 15s 750ms/step - loss: 0.3201 - accuracy: 0.8940 - val_loss: 1.0263 - val_accuracy: 0.6769\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 15s 753ms/step - loss: 0.2576 - accuracy: 0.9128 - val_loss: 1.0827 - val_accuracy: 0.6923\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data_gen,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=valid_data_gen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f2e675",
   "metadata": {},
   "source": [
    "3. Рекурентні нейронні мережі\n",
    "Вирішіть задачу класифікації текстів (з якими ви працювали в лабораторній № 2) за допомогою рекурентної нейромережі. Результати порівняйте з одержаними раніш. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "24c431fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [json.loads(line) for line in open('C:\\\\Users\\\\Studying\\\\Data2\\\\reviews_Amazon_Instant_Video.json', 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "ced35d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.DataFrame(columns = [\"reviewText\", \"overall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "35879ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 100_000):\n",
    "    currentItem = data[i]\n",
    "    reviews.loc[i] = [data[i][\"reviewText\"], data[i][\"overall\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3b3ae70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583933\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for item in data:\n",
    "    counter=counter+1\n",
    "    \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "8a7cb6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (reviews['overall'] == 5.0),\n",
    "    (reviews['overall'] == 1.0) | (reviews['overall'] == 2.0) | (reviews['overall'] == 3.0)]\n",
    "\n",
    "values = [5, 1]\n",
    "\n",
    "reviews['overall'] = np.select(conditions, values)\n",
    "\n",
    "index = reviews[ (reviews['overall'] == 0)].index\n",
    "reviews.drop(index , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "f8ce71d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewText    0\n",
      "overall       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(reviews.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "cea346fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Studying\\AppData\\Local\\Temp\\ipykernel_964\\2147008149.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  reviews['reviewText'] = reviews['reviewText'].str.replace('[^\\w\\s]',' ')\n",
      "C:\\Users\\Studying\\AppData\\Local\\Temp\\ipykernel_964\\2147008149.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  reviews['reviewText'] = reviews['reviewText'].str.replace(r'[0-9]', ' ')\n",
      "C:\\Users\\Studying\\AppData\\Local\\Temp\\ipykernel_964\\2147008149.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  reviews['reviewText'] = reviews['reviewText'].str.replace('[^\\w\\s]',' ')\n",
      "C:\\Users\\Studying\\AppData\\Local\\Temp\\ipykernel_964\\2147008149.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  reviews['reviewText'] = reviews['reviewText'].str.replace(' +', ' ')\n"
     ]
    }
   ],
   "source": [
    "reviews['reviewText'] = reviews['reviewText'].str.lower()\n",
    "reviews['reviewText'] = reviews['reviewText'].str.replace('[^\\w\\s]',' ')\n",
    "reviews['reviewText'] = reviews['reviewText'].str.replace(r'[0-9]', ' ')\n",
    "reviews['reviewText'] = reviews['reviewText'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopWords)]))\n",
    "reviews['reviewText'] = reviews['reviewText'].apply(lambda x: ' '.join([word for word in x.split() if word in (words)]))\n",
    "reviews['reviewText'] = reviews['reviewText'].str.replace('[^\\w\\s]',' ')\n",
    "reviews['reviewText'] = reviews['reviewText'].str.replace(' +', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "6d8d28f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ca lewsi review removed reviewing episode seas...\n",
       "1        truly love humor south park social political c...\n",
       "4        seems like today generation getting revenge ce...\n",
       "5        dont agree reviewer says show wears thin awhil...\n",
       "6        apparently one really thinks drawn together fa...\n",
       "                               ...                        \n",
       "99994    show capture month old son attention let kid w...\n",
       "99995    love ygg son loves program creative great mess...\n",
       "99996    great show fun kids adults refreshing change b...\n",
       "99997    quite different rest two year old loves laughs...\n",
       "99999    grandchildren love yo gabba gabba yet single n...\n",
       "Name: reviewText, Length: 83535, dtype: object"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "0daa4494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ca lewsi review removed reviewing episode season gonna write review whole season episode thats even season reviewing'"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['reviewText'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "6b7a6d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok watched least percent drawn together episodes yet ever recall laughing past grin characters boxed stereotypes leaving absolutely nothing funny obvious predictable jokes never displayed wit adult themed animated shows cant see show lasting many seasons slight premise show tired stuff dawg'"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['reviewText'][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "b82dcfb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great purchase thinking buying sets give gifts package arrived time excellent condition still cellophane wrapped series informative enough without feeling like lesson jean simmons voice captivating especially longer us art works unbelievably beautiful fit narrative perfectly bible scholar cannot speak veracity content say enjoyed set even first saw television'"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['reviewText'][55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "f8f3e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(5000)\n",
    "tokenizer.fit_on_texts(reviews['reviewText'])\n",
    "reviews_tokenized = tokenizer.texts_to_sequences(reviews['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "1f1b6972",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(reviews_tokenized, reviews['overall'], test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "e5f03940",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "3afb47fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad = sequence.pad_sequences(X_train, maxlen=max_seq_len)\n",
    "X_test_pad = sequence.pad_sequences(X_test, maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "38a4589b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  91, 1775,  141,    6,  142, 3530,  848,  630,  109,   13, 1775,\n",
       "        813,  101,   79, 1831])"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad[67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "f2056972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 973,    7,  658, 1783,   21,   89,  506,   11,  112,  204,   92,\n",
       "         37,   67,  696,   20])"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "95b5ab52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80980    5\n",
      "16535    5\n",
      "8104     5\n",
      "61228    5\n",
      "48365    1\n",
      "        ..\n",
      "25345    5\n",
      "54514    5\n",
      "50592    5\n",
      "51684    1\n",
      "81949    1\n",
      "Name: overall, Length: 62651, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "b00baca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(5000, 128))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "1ff3f9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=(['accuracy']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "8212090a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_39 (Embedding)    (None, None, 128)         640000    \n",
      "                                                                 \n",
      " lstm_36 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 771,713\n",
      "Trainable params: 771,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "d622aed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "123/123 [==============================] - 21s 139ms/step - loss: -59.8548 - accuracy: 0.2158\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 18s 146ms/step - loss: -119.8055 - accuracy: 0.2167\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 19s 152ms/step - loss: -170.5038 - accuracy: 0.2167\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 19s 152ms/step - loss: -220.3515 - accuracy: 0.2167\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 19s 152ms/step - loss: -269.7969 - accuracy: 0.2167\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 19s 152ms/step - loss: -319.0171 - accuracy: 0.2167\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 19s 152ms/step - loss: -368.0743 - accuracy: 0.2167\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 19s 152ms/step - loss: -417.0261 - accuracy: 0.2167\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 19s 151ms/step - loss: -465.9201 - accuracy: 0.2167\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 19s 152ms/step - loss: -514.7396 - accuracy: 0.2167\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pad,\n",
    "          Y_train,   \n",
    "          batch_size=512,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbec30c9",
   "metadata": {},
   "source": [
    "Щось тут не так зробив, раніше точніть набагато меншою була, вдалось підвищити до ось цього, але градієнт кудись геть не туди йде(якщо я все правильно зрозумів)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
